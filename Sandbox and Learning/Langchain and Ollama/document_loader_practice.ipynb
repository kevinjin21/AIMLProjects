{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f1891ca",
   "metadata": {},
   "source": [
    "# Practice using different kinds of document loaders.\n",
    "Will be wrapped up in utils/document_loaders.py. \\\n",
    "Can import script to ingest different kinds of unstructured data into text form to be used on LLM.\n",
    "\n",
    "## PPT Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e142ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom file for different document loaders\n",
    "from utils import document_loaders\n",
    "from utils import qna_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c27df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_loader = document_loaders.PowerPointLoader()\n",
    "\n",
    "docs = ppt_loader.load(\"data/ml_course.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671d54ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Slide 1:\\n\\nMachine Learning Model Deployment\\nIntroduction to ML Pipeline\\nhttps://bit.ly/bert_nlp\\n\\n\\n### Slide 2:\\n\\nWhat is Machine Learning Pipeline?\\n\\n\\n### Slide 3:\\n\\nType of ML Deployment\\nBatch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\\nStream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\\nRealtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\\nEdge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.\\n\\n\\n### Slide 4:\\n\\nInfrastructure and Integration\\nHardware and Software: Setting up the right en'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ppt_loader.format_docs(docs)\n",
    "#context = ppt_loader.clean_text(context) # not really necessary for pptx\n",
    "context[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1bba60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are the scripts for each PowerPoint slide:\\n\\n**Slide 1: Machine Learning Model Deployment**\\n\\n[Opening shot of a presentation title]\\n\\nNarrator: \"Welcome to our presentation on machine learning model deployment. In today\\'s digital landscape, deploying machine learning models is crucial for any organization that wants to stay competitive. But with so many options available, it can be overwhelming to choose the right one.\"\\n\\n[Pause for emphasis]\\n\\nNarrator: \"In this presentation, we\\'ll take you through the basics of machine learning pipeline, type of deployment, infrastructure and integration, benefits, challenges, data and model management, A/B testing, security, compliance, and bias. So let\\'s get started!\"\\n\\n**Slide 2: What is Machine Learning Pipeline?**\\n\\n[Visuals of a workflow diagram]\\n\\nNarrator: \"A machine learning pipeline is the process of collecting, processing, and analyzing data to build and deploy machine learning models. It involves several stages, including data ingestion, fe'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "For each PowerPoint slide provided above, write a 2-minute script that effectively conveys the key points.\n",
    "Ensure a smooth flow between slides, maintaining a clear and engaging narrative.\n",
    "\"\"\"\n",
    "response = qna_llm.ask_llm(context, question)\n",
    "response[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26061e4b",
   "metadata": {},
   "source": [
    "### Using save_markdown from document loader class to save to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "049b42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_loader.save_markdown(response, 'llm_reports/ppt_script.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af8027",
   "metadata": {},
   "source": [
    "## Excel Loader\n",
    "Similar operations, but for excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74cb9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from utils import document_loaders\n",
    "from utils import qna_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501d4a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/sample.xlsx', 'file_directory': 'data', 'filename': 'sample.xlsx', 'last_modified': '2025-04-21T14:37:46', 'page_name': 'Data', 'page_number': 1, 'text_as_html': '<table><tr><td>First Name</td><td>Last Name</td><td>City</td><td>Gender</td></tr><tr><td>Brandon</td><td>James</td><td>Miami</td><td>M</td></tr><tr><td>Sean</td><td>Hawkins</td><td>Denver</td><td>M</td></tr><tr><td>Judy</td><td>Day</td><td>Los Angeles</td><td>F</td></tr><tr><td>Ashley</td><td>Ruiz</td><td>San Francisco</td><td>F</td></tr><tr><td>Stephanie</td><td>Gomez</td><td>Portland</td><td>F</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'category': 'Table', 'element_id': 'c44665196e07c27314922db69accb8b6'}, page_content='First Name Last Name City Gender Brandon James Miami M Sean Hawkins Denver M Judy Day Los Angeles F Ashley Ruiz San Francisco F Stephanie Gomez Portland F')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_loader = document_loaders.ExcelLoader()\n",
    "docs = excel_loader.load(\"data/sample.xlsx\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13823694",
   "metadata": {},
   "source": [
    "We preserve the html formatting of the sheet so that the llm can understand the structure of the excel file. This can be later changed to markdown for better visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46d7838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Sheet:\\n\\n<table><tr><td>First Name</td><td>Last Name</td><td>City</td><td>Gender</td></tr><tr><td>Brandon</td><td>James</td><td>Miami</td><td>M</td></tr><tr><td>Sean</td><td>Hawkins</td><td>Denver</td><td>M</td></tr><tr><td>Judy</td><td>Day</td><td>Los Angeles</td><td>F</td></tr><tr><td>Ashley</td><td>Ruiz</td><td>San Francisco</td><td>F</td></tr><tr><td>Stephanie</td><td>Gomez</td><td>Portland</td><td>F</td></tr></table>\\n\\n---'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = excel_loader.format_docs(docs)\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82cad7",
   "metadata": {},
   "source": [
    "Some example llm tasks using this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148e8ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City | Gender |\n",
      "| --- | --- | --- | --- |\n",
      "| Brandon | James | Miami | M |\n",
      "| Sean | Hawkins | Denver | M |\n",
      "| Judy | Day | Los Angeles | F |\n",
      "| Ashley | Ruiz | San Francisco | F |\n",
      "| Stephanie | Gomez | Portland | F |\n"
     ]
    }
   ],
   "source": [
    "question = \"Return this data in Markdown format.\"\n",
    "response = qna_llm.ask_llm(context, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84023e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City    | Gender |\n",
      "|------------|-----------|---------|--------|\n",
      "| Judy       | Day        | Los Angeles | F      |\n",
      "| Ashley     | Ruiz       | San Francisco | F      |\n",
      "| Stephanie  | Gomez      | Portland   | F      |\n"
     ]
    }
   ],
   "source": [
    "question = \"Return all entries in the table where Gender is female. Format the response in Markdown. Only output the resulting table.\"\n",
    "response = qna_llm.ask_llm(context, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6386017",
   "metadata": {},
   "source": [
    "## Microsoft Office data - Word Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c11f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import document_loaders\n",
    "from utils import qna_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954ee7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/job_description.docx'}, page_content='Job Description - Data Scientist\\n\\nAt SpiceJet, we rely on data to provide us valuable insights, and to automate our systems and solutions to help us increase revenues, reduce costs and provide improved customer experiences. We are seeking an experienced data scientist to deliver insights and automate our systems and processes. Ideal team member will have mathematical and statistical expertise, experience with modern data science programming languages and machine learning/AI platforms and techniques. You will mine, clean and interpret our data and then develop machine learning models to deliver business value across different parts of the business. \\n\\nObjectives of this Role\\n\\nUse Data Science and Machine Learning to increase revenue, reduce costs and increase customer satisfaction.\\n\\nCollaborate with product design and engineering to develop an understanding of needs\\n\\nUnderstand where the required data resides and work on ways to extract the relevant data.\\n\\nResearch and devise statistical and machine learning models.\\n\\nCommunicate insights to stakeholders in an automated fashion to enable them to take business decisions.\\n\\nDeploy models in production to automate various processes.\\n\\nSkills and Qualifications\\n\\nBachelor’s degree in Data Science, Computer Science, Statistics, Applied mathematics, or related discipline\\n\\n3+ years experience in data science\\n\\nProficiency with Machine Learning platforms and techniques, data mining, mathematics, and statistical analysis\\n\\nPredictive modelling experience\\n\\nExperience with Python, R, Excel, Tableau, SQL\\n\\nComfortable working in a dynamic, research-oriented group with several ongoing concurrent projects\\n\\nPreferred Qualifications\\n\\nMaster’s degree in Data Science, Computer Science, Stats, Applied math, or related discipline\\n\\n2+ years of project management experience\\n\\nCompetencies:\\n\\nDefining: Can translate fuzzy problem in assigned area into formalized structure\\n\\nTroubleshooting: Can troubleshoot unseen problems in assigned area\\n\\nSolutioning:  Can independently implement the solution\\n\\nCoding Principles: Extensability, Abstraction, Separation of concerns, Chooses right Data Science/Machine learning techniques.\\n\\nCoding Quality: Performant, Integration tests coverage, implements security requirements.\\n\\nProgramming Language Proficiency: Usage of design patterns and knowledge of functional aspects.\\n\\nProject Management: Can break down tasks, identify dependencies and provide accurate effort estimates that feed into the larger plan. Proactively resolve dependencies and communicate around progress and blockers.\\n\\nExecution: Responsible for timely completion of assigned components including integration and deployment to appropriate environments. Complete ownership of quality including iterations with stakeholders to meet the desired objectives.\\n\\nResponsiveness: Understands team priorities. Own, identify and quick turn around for production issues that address the root cause.\\n\\nDesigning: Low level design, functional modeling, Adaptability, High level design with guidance\\n\\nAnalysis: Understanding impact of design changes\\n\\nNon Functional Attributes: Understands the basic concepts around performance and can contribute to measuring and improving performance. Understands scalability\\n\\nData Orientation: Apply algorithms to make smarter and intelligent data driven systems, Good understanding and know hows of various data tools/tech (e.g. Data Tools, IR and ML tools)')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_loader = document_loaders.WordLoader()\n",
    "docs = docx_loader.load(\"data/job_description.docx\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba1cc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Description - Data Scientist At SpiceJet, we rely on data to provide us valuable insights, and to automate our systems and solutions to help us increase revenues, reduce costs and provide improved customer experiences. We are seeking an experienced data scientist to deliver insights and automate our systems and processes. Ideal team member will have mathematical and statistical expertise, experience with modern data science programming languages and machine learning/AI platforms and techniques. You will mine, clean and interpret our data and then develop machine learning models to deliver business value across different parts of the business. Objectives of this Role Use Data Science and Machine Learning to increase revenue, reduce costs and increase customer satisfaction. Collaborate with product design and engineering to develop an understanding of needs Understand where the required data resides and work on ways to extract the relevant data. Research and devise statistical and ma'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = docx_loader.format_docs(docs)\n",
    "context = docx_loader.clean_text(context)\n",
    "context[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66143196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Data Scientist Position at SpiceJet\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Data Scientist position at SpiceJet. As a recent graduate from MIT with a focus on NLP and ML, I am confident that my skills and expertise align well with the requirements of this role.\n",
      "\n",
      "With a strong foundation in mathematical and statistical techniques, I have developed proficiency in machine learning platforms and techniques, data mining, mathematics, and statistical analysis. My experience with Python, R, Excel, Tableau, and SQL enables me to effectively extract insights from data and develop predictive models.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to apply my skills to drive business value across different parts of the business. I am excited about the prospect of collaborating with product design and engineering to understand customer needs and developing solutions that increase revenue, reduce costs, and improve customer satisfaction.\n",
      "\n",
      "Throughout my academic journey, I have developed a solid understanding of data science principles, including defining problems, troubleshooting unseen issues, and implementing effective solutions. My experience in machine learning has equipped me with the ability to translate fuzzy problems into formalized structures and troubleshoot complex issues.\n",
      "\n",
      "I am confident that my skills, passion for data science, and enthusiasm for this role make me an ideal candidate for the Data Scientist position at SpiceJet. I would welcome the opportunity to discuss how I can contribute to the success of your team.\n",
      "\n",
      "Thank you for considering my application.\n",
      "\n",
      "Sincerely,\n",
      "Frank\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "My name is Frank. I am a recent graduate from MIT with a focus on NLP and ML. \n",
    "I am applying for a Data Scientist position at SpiceJet.\n",
    "Please write a concise job application email for me, removing any placeholders, including references to job boards or sources.\n",
    "\"\"\"\n",
    "\n",
    "response = qna_llm.ask_llm(context, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859de94",
   "metadata": {},
   "source": [
    "## Potential future work for this concept:\n",
    "Use your own resume as additional context. Ask the llm to generate a cover letter based on skills/info from your resume, match to what the job description is asking for. This can be done by just combining the two as a single context to pass in, or can create a chain to take in two separate contexts and return the desired description/cover letter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc429b8b",
   "metadata": {},
   "source": [
    "# Youtube video transcripts and SEO keywords\n",
    "Extract youtube transcripts and send to LLM to perform desired tasks. NOTE: couldn't get description and info to work, seems to be an issue with pytube which langchain_community is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9804d530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from utils.document_loaders import YouTubeLoader\n",
    "from utils import qna_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6468b26",
   "metadata": {},
   "source": [
    "### Configured youtube loader to already chunk the transcript based on user-defined chunk_size_seconds.\n",
    "Transcripts often go long (especially longer videos). This allows pre-chunking to be built into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b64cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcp explained youtube video\n",
    "url = 'https://www.youtube.com/watch?v=_d0duu3dED4'\n",
    "yt_loader = YouTubeLoader()\n",
    "docs = yt_loader.load(url, chunk_size_seconds=180) # set the chunk size in seconds. Default is 600 (5min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce646fb3",
   "metadata": {},
   "source": [
    "2 chunks based on 3 minute chunks (video is <5min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c143a0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa754ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Untitled--Timestamp: 00:00:00\\n\\nToday we're diving into the model context protocol or MCP. One of the most significant advancements in LLM integration released by Anthropic in late 2024. So what exactly is MCP? At its core, the model context protocol is an open standard that enables seamless integration between AI models like claude and external data sources or tools. is addressing a fundamental limitation that has held back AI assistance from reaching their potential. Before MCP, connecting models to each new data source require custom implementations, which can get expensive. MCB solves this by providing a universal open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. This means we can give AI systems access to databases, file systems, APIs, and other tools in a standardized way. Let's break down the architecture. MCP follows a client server models with three key components. Hosts, clients, and servers. Host are LLM a\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = yt_loader.format_docs(docs)\n",
    "context[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba52789",
   "metadata": {},
   "source": [
    "### Use LLM to generate youtube video keywords \n",
    "SEO tool to generate keywords based on youtube transcript. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208ca593",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "You are an assistant for generating SEO keywords for YouTube.\n",
    "Please generate a list of keywords from the above context.\n",
    "Be creative and correct spelling if needed.\n",
    "\"\"\"\n",
    "\n",
    "keywords = []\n",
    "for doc in docs:\n",
    "    kws = qna_llm.ask_llm(context=doc.page_content, question=question)\n",
    "    keywords.append(kws)\n",
    "\n",
    "keywords = ', '.join(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccc73360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a list of SEO keywords based on the provided context:\n",
      "\n",
      "**Main Keywords:**\n",
      "\n",
      "1. Model Context Protocol (MCP)\n",
      "2. AI Integration\n",
      "3. Artificial Intelligence (AI) Assistance\n",
      "4. Natural Language Processing (NLP)\n",
      "\n",
      "**Long-Tail Keywords:**\n",
      "\n",
      "1. Standardized integration for AI models and external data sources\n",
      "2. Seamless AI model connections\n",
      "3. Universal protocol for AI system access\n",
      "4. Open standard for AI assistance\n",
      "5. Secure file access for AI applications\n",
      "6. Executable functions in AI model context\n",
      "7. Prompt-based instruction injection\n",
      "8. Structured data objects for AI reference\n",
      "9. Client-server architecture for AI integration\n",
      "10. Server-side capabilities for AI tools\n",
      "\n",
      "**Keyword Phrases:**\n",
      "\n",
      "1. \"MCP enables seamless AI model connections\"\n",
      "2. \"Standardized protocol for AI system access\"\n",
      "3. \"Seamless integration of AI and external data sources\"\n",
      "4. \"Secure file access for AI applications\"\n",
      "5. \"Prompt-based instruction injection in AI models\"\n",
      "\n",
      "Feel free to modify or expand these keywords as needed for your YouTube SEO content!, Based on the provided context, here's a list of potential SEO keywords:\n",
      "\n",
      "1. Machine Learning Protocol (MCP)\n",
      "2. AI Landscape\n",
      "3. Integrations with LLMs\n",
      "4. Cloud Integration\n",
      "5. Data Analysis Tools\n",
      "6. Postgress Integration\n",
      "7. MCP Server\n",
      "8. MCP Client\n",
      "9. Artificial Intelligence Protocols\n",
      "10. System Design Trends\n",
      "11. Large Scale System Design\n",
      "12. Open Source Technology\n",
      "13. AI Application Development\n",
      "14. Data Source Interactions\n",
      "15. DevOps for Machine Learning\n",
      "16. MCP Ecosystem\n",
      "17. Cloud-Based Integration Solutions\n",
      "18. AI-Driven System Design\n",
      "\n",
      "Some potential long-tail keywords could be:\n",
      "\n",
      "* \"MCP protocol for integrating LLMs with cloud services\"\n",
      "* \"Cloud-based data analysis tools using Postgress and MCP\"\n",
      "* \"Developing sophisticated AI applications with diverse data sources\"\n",
      "* \"Open source machine learning protocols for enterprise adoption\"\n",
      "* \"System design trends in large scale AI landscapes\"\n",
      "\n",
      "Note that some of these keywords may be more relevant to specific niches or industries, such as DevOps, Machine Learning, or Cloud Computing.\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81468d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
