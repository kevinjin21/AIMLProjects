{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe8e1eee",
   "metadata": {},
   "source": [
    "# Linkedin Profile Scraper Project\n",
    "Return profile information via linkedin login. Combining the power of Selenium to parse webpages and LLM to understand the parsed context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1f4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env imports\n",
    "import warnings, os\n",
    "warnings.filterwarnings('ignore')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# webscraping imports\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "import json\n",
    "\n",
    "# llm imports\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "base_url='http://localhost:11434'\n",
    "model='llama3.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b26e25",
   "metadata": {},
   "source": [
    "### Testing Selenium connection and login credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e7ea5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinkedIn Login, Sign in | LinkedIn'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "driver.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea86a49",
   "metadata": {},
   "source": [
    "### Successfully log into Linkedin account and uncheck 'Remember me' box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2abe4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find fields and send creds from .env\n",
    "email = driver.find_element(By.ID, 'username')\n",
    "email.send_keys(os.getenv('LINKEDIN_USER'))\n",
    "password = driver.find_element(By.ID, 'password')\n",
    "password.send_keys(os.getenv('LINKEDIN_PASS'))\n",
    "\n",
    "# Find and uncheck the remember me checkbox\n",
    "try:\n",
    "    # Wait for the checkbox to be present and interactable\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    checkbox = wait.until(EC.presence_of_element_located((By.ID, 'rememberMeOptIn-checkbox')))\n",
    "    \n",
    "    # Check if it's selected and uncheck if needed\n",
    "    if checkbox.get_attribute('checked') is not None:\n",
    "        # Try JavaScript click as a more reliable method\n",
    "        driver.execute_script(\"arguments[0].click();\", checkbox)\n",
    "        # Verify the change\n",
    "        if checkbox.get_attribute('checked') is not None:\n",
    "            print(\"Warning: Checkbox may still be checked\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find or interact with remember me checkbox: {str(e)}\")\n",
    "\n",
    "password.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107b799",
   "metadata": {},
   "source": [
    "### Optional/For future project:\n",
    "Scraping job listings would be more useful to me than scraping profiles. See if I can get into the Jobs page and get some listing html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6445a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully clicked Jobs button\n"
     ]
    }
   ],
   "source": [
    "# Wait for the Jobs link to be clickable\n",
    "try:\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    jobs_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[href*='/jobs/?']\")))\n",
    "    \n",
    "    # Alternative selectors if the above doesn't work\n",
    "    # jobs_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//span[text()='Jobs']/ancestor::a\")))\n",
    "    # jobs_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[data-test-app-aware-link] span[title='Jobs']\")))\n",
    "    \n",
    "    jobs_button.click()\n",
    "    print(\"Successfully clicked Jobs button\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find or click Jobs button: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d3fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully clicked 'Show all' button using alternative method\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    show_all_button = driver.find_element(\n",
    "        By.XPATH, \n",
    "        \"//a[contains(@class, 'artdeco-button') and .//span[text()='Show all']]\"\n",
    "    )\n",
    "    driver.execute_script(\"arguments[0].click();\", show_all_button)\n",
    "    print(\"Successfully clicked 'Show all' button\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find or click 'Show all' button: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc45e285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted job details\n"
     ]
    }
   ],
   "source": [
    "# After navigating to a job listing page\n",
    "try:\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    job_details_div = wait.until(EC.presence_of_element_located((\n",
    "        By.CSS_SELECTOR, \n",
    "        \"div.jobs-details__main-content--single-pane\"\n",
    "    )))\n",
    "    \n",
    "    # Extract the HTML content\n",
    "    job_html = job_details_div.get_attribute('innerHTML')\n",
    "    \n",
    "    # Parse with BeautifulSoup\n",
    "    job_soup = BeautifulSoup(job_html, 'lxml')\n",
    "\n",
    "    # Extract text content\n",
    "    job_text = clean_text(job_soup.get_text())\n",
    "    \n",
    "    print(\"Successfully extracted job details\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not extract job details: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e559d327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTikTok\\nShare\\nShow more options\\nData Scientist, Product Analytics - USDS\\xa0\\nMountain View, CA · Reposted 2 weeks ago · Over 100 people clicked apply\\n$114K/yr - $177.8K/yrMatches your job preferences, minimum pay preference is 120000.\\nApply\\nSave\\nSave Data Scientist, Product Analytics - USDS\\xa0  at TikTok\\nData Scientist, Product Analytics - USDS\\nTikTok · Mountain View, CA\\nApply\\nSave\\nSave Data Scientist, Product Analytics - USDS\\xa0  at TikTok\\nShow more options\\nHow your profile and resume fit this job\\nGet AI-powered advice on this job and more exclusive features with Premium.\\nRetry Premium for $0\\nTailor my resume to this job\\nAm I a good fit for this job?\\nHow can I best position myself for this job?\\nPeople you can reach out to\\nApache Corporation logo\\nCompany alumni from Apache Corporation and others in your network\\nShow all\\nAbout the job\\nResponsibilitiesAbout the teamThe Data Science team of the Tech and Product department at TikTok USDS is responsible for building high-quality and timely data so'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM PROMPT ###\n",
    "template = \"\"\"\n",
    "Extract and return key job information from the LinkedIn job listing in a structured format.\n",
    "\n",
    "### Job Listing Data:\n",
    "{}\n",
    "\n",
    "### Information to Extract:\n",
    "- Job Title\n",
    "- Company\n",
    "- Location\n",
    "- Employment Type\n",
    "- Required Skills\n",
    "- Job Description\n",
    "- Requirements\n",
    "- Benefits\n",
    "\n",
    "### Extracted Data:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c393b",
   "metadata": {},
   "source": [
    "## Scrape desired profile\n",
    "Now that we've successfully logged in, we can scrape a desired page. Note: Linkedin does have limits on scrapes per day, so be aware of this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ecb28861",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.linkedin.com/in/kevinjin7'\n",
    "driver.get(url)\n",
    "page_source = driver.page_source # html for scraped url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd62d4",
   "metadata": {},
   "source": [
    "### Had to do some delay and scrolling to load the full page. Content is not fully loaded immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84f4099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 profile sections\n"
     ]
    }
   ],
   "source": [
    "# Navigate to profile\n",
    "url = 'https://www.linkedin.com/in/kevinjin7'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for initial page load and scroll to load dynamic content\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Wait for the profile sections to be present\n",
    "try:\n",
    "    # First wait for any artdeco-card to appear\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'artdeco-card')))\n",
    "    \n",
    "    # Scroll slowly through the page to trigger lazy loading\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        # Scroll down in smaller increments\n",
    "        for i in range(10):\n",
    "            driver.execute_script(f\"window.scrollTo(0, {last_height * (i/10)});\")\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        # Wait for new content\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Calculate new scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    # Scroll back to top\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Now get the fully loaded page source\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    \n",
    "    # Find sections and print count for debugging\n",
    "    sections = soup.find_all('section', {'class': 'artdeco-card'})\n",
    "    print(f\"Found {len(sections)} profile sections\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading profile content: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21cf966",
   "metadata": {},
   "source": [
    "## Preprocessing html to feed to LLM\n",
    "LLM context window runs into issues with entire page of html. Preprocess via bs4 and clean up before sending to LLM for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf53bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab text from sections\n",
    "sections_text = [section.get_text() for section in sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33b1d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove multiple newlines and tabs\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'\\t+', '\\t', text)\n",
    "    text = re.sub(r'\\t\\s+', ' ', text)\n",
    "    text = re.sub(r'\\n\\s+', '\\n', text)\n",
    "\n",
    "    # remove duplicates in each line. this is sometimes a scraped formatting issue for this page. See sections[2]\n",
    "    lines = text.split('\\n')\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        if line[:len(line)//2] == line[len(line)//2:]:\n",
    "            new_lines.append(line[:len(line)//2])\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "\n",
    "    return '\\n'.join(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "074a6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean sections\n",
    "sections_text = [clean_text(section) for section in sections_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aaa20780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sections: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nKevin Jin\\nData Science | Machine Learning Engineer\\nApache Corporation\\nUniversity of California, Los Angeles\\nHouston, Texas, United States\\nContact info\\nhttps://kevinjin.crd.co/\\n291 connections\\nOpen to\\nAdd profile section\\nEnhance profile\\nSend profile in a message\\nSave to PDF\\nSaved items\\nActivity\\nAbout this profile\\nAbout this profile\\nEnhance profile\\nTell non-profits you're interested in getting involved with your time and skills\\nGet started\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sections: \" + str(len(sections_text)))\n",
    "sections_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052feb0e",
   "metadata": {},
   "source": [
    "## Feed text to LLM\n",
    "Now that the text has been (somewhat) cleaned, it is ready to be fed into the LLM for processing. Note that depending on the LLM, trying to parse the entire profile as a whole may be outside of the context size. In this case, we just process section by section, which solves this issue. However, other scraping projects may have large volumes of data, so it is something to keep in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "210bccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(llm, prompt, system=None):\n",
    "    # default system message if not provided\n",
    "    if system is None:\n",
    "        system = SystemMessagePromptTemplate.from_template(\"\"\"You are helpful AI assistant who answer LinkedIn profile parsing related \n",
    "                                                    user question based on the provided profile text data.\"\"\")\n",
    "\n",
    "    prompt = HumanMessagePromptTemplate.from_template(prompt)\n",
    "\n",
    "    messages = [system, prompt]\n",
    "    template = ChatPromptTemplate(messages)\n",
    "\n",
    "    qna_chain = template | llm | StrOutputParser()\n",
    "\n",
    "    return qna_chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "300d50db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nExtract and return the requested information from the LinkedIn profile data in a concise, point-by-point format (up to 5 points). Avoid preambles or any additional context.\\n\\n### LinkedIn Profile Data:\\n\\nKevin Jin\\nData Science | Machine Learning Engineer\\nApache Corporation\\nUniversity of California, Los Angeles\\nHouston, Texas, United States\\nContact info\\nhttps://kevinjin.crd.co/\\n291 connections\\nOpen to\\nAdd profile section\\nEnhance profile\\nSend profile in a message\\nSave to PDF\\nSaved items\\nActivity\\nAbout this profile\\nAbout this profile\\nEnhance profile\\nTell non-profits you're interested in getting involved with your time and skills\\nGet started\\n\\n\\n### Information to Extract:\\nExtract 'Name and Headline' in bullet points, limiting the output to 5 points. Provide only the necessary details.\\nRemember, It is LinkedIn profile data.\\n\\n### Extracted Data:\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = sections_text[0]\n",
    "key = 'Name and Headline'\n",
    "\n",
    "template = \"\"\"\n",
    "Extract and return the requested information from the LinkedIn profile data in a concise, point-by-point format (up to 5 points). Avoid preambles or any additional context.\n",
    "\n",
    "### LinkedIn Profile Data:\n",
    "{}\n",
    "\n",
    "### Information to Extract:\n",
    "Extract '{}' in bullet points, limiting the output to 5 points. Provide only the necessary details.\n",
    "Remember, It is LinkedIn profile data.\n",
    "\n",
    "### Extracted Data:\"\"\"\n",
    "\n",
    "prompt = template.format(context, key) # context and key will be formatted into {} placeholders in prompt\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a0fbf430",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template(\"\"\"You are helpful AI assistant who answer LinkedIn profile parsing related \n",
    "                                                    user question based on the provided profile text data.\"\"\")\n",
    "\n",
    "response = ask_llm(llm, prompt, system) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "879bca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Name: Kevin Jin\n",
      "* Headline: Data Science | Machine Learning Engineer\n",
      "* Current Company: Apache Corporation\n",
      "* University: University of California, Los Angeles\n",
      "* Location: Houston, Texas, United States\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d541a",
   "metadata": {},
   "source": [
    "### Get section headers to give to LLM\n",
    "Not all sections need to be parsed (some links to other profiles and other items). We can also use the header to tell the LLM what it is looking for. For example, we want to extract the 'about' information from the 'About' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c8289947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name and Headline',\n",
       " \"Tell non-profits you're interested in getting involved with your time and skills\",\n",
       " 'Analytics',\n",
       " 'About',\n",
       " 'Featured',\n",
       " 'Activity',\n",
       " 'Experience',\n",
       " 'Education',\n",
       " 'Projects',\n",
       " 'Skills',\n",
       " 'Interests']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_keys = ['Name and Headline']\n",
    "for section in sections_text[1:11]:\n",
    "    section_keys.append(section.strip().split('\\n')[0])\n",
    "\n",
    "section_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d20f9",
   "metadata": {},
   "source": [
    "### Generate extracted responses\n",
    "For each key in section keys, the LLM will extract the relevant info from each matching section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "216e9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {}\n",
    "\n",
    "for k,context in zip(section_keys, sections_text):\n",
    "    prompt = template.format(context, k)\n",
    "    response = ask_llm(llm, prompt)\n",
    "    responses[k] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6d8dfe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name and Headline': '* Name: Kevin Jin\\n* Title: \\n* Current Company: Apache Corporation\\n* Past Education: University of California, Los Angeles',\n",
       " \"Tell non-profits you're interested in getting involved with your time and skills\": \"• Tell non-profits you're interested in getting involved with your time and skills\\n• Get started\",\n",
       " 'Analytics': '* Private to you\\n* 61 profile views\\n* 0 post impressions\\n* 32 search appearances\\n* Show all analytics',\n",
       " 'About': '• Born and raised in Houston, Texas\\n• Attended UCLA in Los Angeles for Electrical Engineering\\n• Worked in Hwaseong, South Korea after studies\\n• Currently working at Apache Corporation\\n• Loves to explore new places and try new restaurants',\n",
       " 'Featured': \"• Link\\n• Personal Projects: My ML Story\\n• Kevin's ML Portfolio\\n• Featured \\n• I’ve always been a big fan of learning and making connections through what I see and observe\",\n",
       " 'Activity': '* 292 followers\\n* Create a post\\n* You haven’t posted yet\\n* Posts you share will be displayed here.\\n* Show all activity',\n",
       " 'Experience': '• Data Analyst \\nApache Corporation (Nov 2023 - Present) \\n• Machine Learning Engineering Fellow \\nUC San Diego Extended Studies (Apr 2023 - Oct 2023) \\n• Senior Instructor \\nCHUNGDAHM Learning (Mar 2021 - Feb 2023) \\n• Online Tutor \\nSparks Academy (Jul 2020 - Feb 2021)',\n",
       " 'Education': '• UCLA\\nElectrical and Computer Engineering, Computer Science (2015 - 2019)\\n• UC San Diego Extended Studies \\nMachine Learning Engineering Bootcamp (May 2023 - Sep 2023) \\n• UCSD Extended Studies ML',\n",
       " 'Projects': '• Disney+ Recommendation System\\n• Jun 2023 - Aug 2023\\n• Associated with UC San Diego Extended Studies\\n• Scikit-Learn, Data Analysis and \\n• Create a content-based recommendation system for shows and movies from Disney+.',\n",
       " 'Skills': '• LangChain\\n• Data Analyst\\n• Palantir \\n• Apache Corporation',\n",
       " 'Interests': '• No interests mentioned in the provided LinkedIn profile data.'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f4e8c",
   "metadata": {},
   "source": [
    "### Optional: Save to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "19c7e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('linkedin_profile_data.json', 'w') as f:\n",
    "    json.dump(responses, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9621f",
   "metadata": {},
   "source": [
    "## Adding another LLM layer to further customize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a0d60e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are provided with LinkedIn profile data in JSON format.\n",
    "            Parse the data according to the specified schema, correct any spelling errors,\n",
    "            and condense the information if possible.\n",
    "\n",
    "### LinkedIn Profile JSON Data:\n",
    "{context}\n",
    "\n",
    "### Schema You need to follow:\n",
    "You need to extract\n",
    "Name:\n",
    "Headline:\n",
    "About:\n",
    "Experience:\n",
    "Education:\n",
    "Skills:\n",
    "Projects:\n",
    "Summary:\n",
    "\n",
    "Do not return preambles or any other information.\n",
    "### Parsed Data:\"\"\"\n",
    "\n",
    "prompt2 = template.format(context=responses).replace(\"{\", \"{{\").replace(\"}\", \"}}\") # fixing json formatting\n",
    "response_2 = ask_llm(llm, prompt=prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "91346ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Name\": \"Kevin Jin\",\n",
      "  \"Headline\": \"\",\n",
      "  \"About\": \"Born and raised in Houston, Texas\\nAttended UCLA in Los Angeles for Electrical Engineering\\nWorked in Hwaseong, South Korea after studies\\nCurrently working at Apache Corporation\\nLoves to explore new places and try new restaurants\",\n",
      "  \"Experience\":\n",
      "  [\n",
      "    \"Data Analyst \",\n",
      "    \"Apache Corporation (Nov 2023 - Present)\",\n",
      "    \"Machine Learning Engineering Fellow \",\n",
      "    \"UC San Diego Extended Studies (Apr 2023 - Oct 2023)\",\n",
      "    \"Senior Instructor \",\n",
      "    \"CHUNGDAHM Learning (Mar 2021 - Feb 2023)\",\n",
      "    \"Online Tutor \",\n",
      "    \"Sparks Academy (Jul 2020 - Feb 2021)\"\n",
      "  ],\n",
      "  \"Education\":\n",
      "  [\n",
      "    \"UCLA\",\n",
      "    \"Electrical and Computer Engineering, Computer Science (2015 - 2019)\",\n",
      "    \"UC San Diego Extended Studies \",\n",
      "    \"Machine Learning Engineering Bootcamp (May 2023 - Sep 2023)\",\n",
      "    \"UCSD Extended Studies ML\"\n",
      "  ],\n",
      "  \"Skills\": \n",
      "  [\n",
      "    \"LangChain\",\n",
      "    \"Data Analyst\",\n",
      "    \"Palantir\",\n",
      "    \"Apache Corporation\"\n",
      "  ],\n",
      "  \"Projects\": \n",
      "  [\n",
      "    \"Disney+ Recommendation System\",\n",
      "    \"Jun 2023 - Aug 2023\",\n",
      "    \"Associated with UC San Diego Extended Studies\",\n",
      "    \"Scikit-Learn, Data Analysis and \"\n",
      "  ],\n",
      "  \"Summary\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32f8cc",
   "metadata": {},
   "source": [
    "# NOTE: \n",
    "This output may not be that refined. This is because we're using Llama3:3.2b, which is not a very big model. Using a bigger model will generate better results, but for the sake of this demo, we kept it simple. There is a lot of room to improve on this! From better field key extraction to having the llm better understand and parse fields. Will be interesting to potentially use this in a future project (especially nice to learn selenium as a side quest)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
