{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09aaf99",
   "metadata": {},
   "source": [
    "# Resume Parsing Project\n",
    "Extract information in json format and create streamlit application as a UI. IDEA: Later project may be to extract linkedin job posting information given a url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6267eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701be70",
   "metadata": {},
   "source": [
    "### Extract Text Data (pymupdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ddb3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Old Resume.docx'\n",
    "\n",
    "loader = PyMuPDFLoader('sample_resumes/{}'.format(filename))\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e9934",
   "metadata": {},
   "source": [
    "### Feed text to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7998529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = docs[0].page_content\n",
    "\n",
    "question = \"\"\"You are tasked with parsing a job resume. Your goal is to extract relevant information in a valid structured 'JSON' format. \n",
    "                Do not write preambles or explanations.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5800e718",
   "metadata": {},
   "source": [
    "### Prepare LLM context and formattting\n",
    "To specifically and accurately extract desired information, we need to provide some structure and instructions to the LLM. This will be done in llm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b9e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get llm tools from llm.py\n",
    "from scripts.llm import ask_llm, validate_json\n",
    "# ask llm: extracts desired information from resume in pre-defined format\n",
    "# validate_json: ensures output is validn JSON with no extra text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c4a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_llm(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up response\n",
    "response = validate_json(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09cc9f",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "App currently sits on local machine. Course goes on to use AWS EC2 instance to host the application. \n",
    "\n",
    "Example tutorial of creating simple aws instance: https://towardsdatascience.com/aws-deploying-a-fastapi-app-on-ec2-in-minutes/\n",
    "\n",
    "Note: best way to deploy is probably by configuring docker container. This will need more config and work. Make sure the instance has enough CPUs to run an LLM tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
